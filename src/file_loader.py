from __future__ import annotations

import json
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Optional

import pandas as pd


@dataclass
class WeeklyData:
    schedule_raw: dict
    stats_raw: dict
    wgr_raw: dict
    fanduel_players: pd.DataFrame

    schedule_tournaments: pd.DataFrame
    player_stats: pd.DataFrame
    wgr_players: pd.DataFrame

    def get_course_meta(self, tournament_id: str) -> Optional[dict]:
        try:
            t = next(x for x in self.schedule_raw.get("tournaments", []) if x.get("id") == tournament_id)
        except Exception:
            return None

        venue = (t.get("venue") or {})
        courses = venue.get("courses") or []
        if not courses:
            return None
        c0 = courses[0] or {}
        return {
            "venue": venue.get("name"),
            "course_name": c0.get("name"),
            "yardage": c0.get("yardage"),
            "par": c0.get("par"),
        }


def list_week_folders(weekly_root: Path) -> list[str]:
    if not weekly_root.exists():
        return []
    folders = [p.name for p in weekly_root.iterdir() if p.is_dir()]
    folders.sort(reverse=True)
    return folders


def _read_json_bytes(b: bytes) -> dict:
    return json.loads(b.decode("utf-8"))


def _read_json_path(p: Path) -> dict:
    return json.loads(p.read_text(encoding="utf-8"))


def load_weekly_data(
    folder: Optional[Path],
    schedule_bytes: Optional[bytes] = None,
    stats_bytes: Optional[bytes] = None,
    wgr_bytes: Optional[bytes] = None,
    fanduel_bytes: Optional[bytes] = None,
) -> WeeklyData:
    """
    Loads weekly data from either:
      A) a folder with fixed filenames, or
      B) uploaded bytes.
    """

    if folder is not None:
        schedule_raw = _read_json_path(folder / "schedule.json")
        stats_raw = _read_json_path(folder / "player_statistics.json")
        wgr_raw = _read_json_path(folder / "wgr_rankings.json")
        fanduel_df = pd.read_csv(folder / "fanduel_players.csv")
    else:
        assert schedule_bytes and stats_bytes and wgr_bytes and fanduel_bytes
        schedule_raw = _read_json_bytes(schedule_bytes)
        stats_raw = _read_json_bytes(stats_bytes)
        wgr_raw = _read_json_bytes(wgr_bytes)
        # FanDuel CSV bytes
        fanduel_df = pd.read_csv(pd.io.common.BytesIO(fanduel_bytes))

    # ---- schedule tournaments ----
    tournaments = schedule_raw.get("tournaments", []) or []
    sched_rows = []
    for t in tournaments:
        sched_rows.append({
            "id": t.get("id"),
            "name": t.get("name"),
            "start_date": t.get("start_date"),
            "end_date": t.get("end_date"),
            "event_type": t.get("event_type"),
            "status": t.get("status"),
        })
    schedule_tournaments = pd.DataFrame(sched_rows).dropna(subset=["id", "name"])

    # ---- player stats ----
    # Some SportsRadar payloads use "players"; your file does. :contentReference[oaicite:4]{index=4}
    stats_players = stats_raw.get("players", stats_raw.get("player", [])) or []
    stat_rows = []
    for p in stats_players:
        s = p.get("statistics") or {}
        stat_rows.append({
            "player_id": p.get("id"),
            "first_name": p.get("first_name"),
            "last_name": p.get("last_name"),
            "abbr_name": p.get("abbr_name"),
            # Common scoring/skill stats present in your file :contentReference[oaicite:5]{index=5}
            "scoring_avg": s.get("scoring_avg"),
            "birdies_per_round": s.get("birdies_per_round"),
            "gir_pct": s.get("gir_pct"),
            "scrambling_pct": s.get("scrambling_pct"),
            "drive_avg": s.get("drive_avg"),
            "drive_acc": s.get("drive_acc"),
            "putt_avg": s.get("putt_avg"),
            "sand_saves_pct": s.get("sand_saves_pct"),
            "total_driving": s.get("total_driving"),
            "world_rank": s.get("world_rank"),
            # Strokes gained fields you have :contentReference[oaicite:6]{index=6}
            "strokes_gained": s.get("strokes_gained"),
            "strokes_gained_total": s.get("strokes_gained_total"),
            "strokes_gained_tee_green": s.get("strokes_gained_tee_green"),
        })
    player_stats = pd.DataFrame(stat_rows).dropna(subset=["player_id"])

    # ---- WGR players ----
    wgr_players_raw = wgr_raw.get("players", []) or []
    wgr_rows = []
    for p in wgr_players_raw:
        wgr_rows.append({
            "player_id": p.get("id"),
            "wgr_first_name": p.get("first_name"),
            "wgr_last_name": p.get("last_name"),
            "wgr_rank": p.get("rank"),
        })
    wgr_players = pd.DataFrame(wgr_rows).dropna(subset=["player_id"])

    return WeeklyData(
        schedule_raw=schedule_raw,
        stats_raw=stats_raw,
        wgr_raw=wgr_raw,
        fanduel_players=_normalize_fanduel(fanduel_df),
        schedule_tournaments=schedule_tournaments,
        player_stats=_coerce_numeric(player_stats),
        wgr_players=_coerce_numeric(wgr_players),
    )


def _coerce_numeric(df: pd.DataFrame) -> pd.DataFrame:
    out = df.copy()
    for c in out.columns:
        if c in {"player_id", "first_name", "last_name", "abbr_name", "wgr_first_name", "wgr_last_name"}:
            continue
        out[c] = pd.to_numeric(out[c], errors="ignore")
    return out


def _normalize_fanduel(fd: pd.DataFrame) -> pd.DataFrame:
    """
    FanDuel PGA CSV format varies slightly, but your file has:
      Id, First Name, Last Name, FPPG, Salary
    """
    df = fd.copy()

    # Standardize column names
    rename_map = {}
    for col in df.columns:
        c = col.strip()
        if c.lower() == "first name":
            rename_map[col] = "First Name"
        if c.lower() == "last name":
            rename_map[col] = "Last Name"
        if c.lower() == "salary":
            rename_map[col] = "Salary"
        if c.lower() == "fppg":
            rename_map[col] = "FPPG"
        if c.lower() == "id":
            rename_map[col] = "Id"
    df = df.rename(columns=rename_map)

    needed = ["Id", "First Name", "Last Name", "Salary", "FPPG"]
    for n in needed:
        if n not in df.columns:
            raise ValueError(f"FanDuel CSV missing required column: {n}")

    df["Salary"] = pd.to_numeric(df["Salary"], errors="coerce")
    df["FPPG"] = pd.to_numeric(df["FPPG"], errors="coerce")
    df = df.dropna(subset=["Salary"]).copy()

    df["fd_name"] = (df["First Name"].fillna("").astype(str).str.strip() + " " + df["Last Name"].fillna("").astype(str).str.strip()).str.strip()
    return df

